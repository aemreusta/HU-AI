{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlrnwcgpCfBQ"
      },
      "source": [
        "# Necessary Imports and Data Readings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbDgnssZBM2q"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import matplotlib.pyplot as plt\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "work_dir = \"/Users/emre/GitHub/HU-AI/AIN433/Assignment 1/\"\n",
        "DATASET_PATH = os.path.join(work_dir, \"dataset\")\n",
        "IMAGES_PATH = os.path.join(DATASET_PATH, \"images\")\n",
        "ANNOTATIONS_PATH = os.path.join(DATASET_PATH, \"annotations\")\n",
        "RESULTS_PATH = os.path.join(work_dir, \"results\")\n",
        "\n",
        "# Using glob to read image file names directly\n",
        "png_img_list = [img for img in glob.glob(os.path.join(IMAGES_PATH, \"*.png\"))]\n",
        "\n",
        "# File existence check is redundant if files are directly read into the list\n",
        "print(f\"Number of images: {len(png_img_list)}\")\n",
        "\n",
        "# Optimizing XML reading and parsing\n",
        "xml_files = glob.glob(os.path.join(ANNOTATIONS_PATH, \"*.xml\"))\n",
        "xml_coordinates = {\n",
        "    os.path.join(IMAGES_PATH, ET.parse(xml_file).find(\"filename\").text): [\n",
        "        int(ET.parse(xml_file).find(\".//xmin\").text),\n",
        "        int(ET.parse(xml_file).find(\".//ymin\").text),\n",
        "        int(ET.parse(xml_file).find(\".//xmax\").text),\n",
        "        int(ET.parse(xml_file).find(\".//ymax\").text),\n",
        "    ]\n",
        "    for xml_file in xml_files\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgayrppDC5tT"
      },
      "source": [
        "# Sobel Edge Detector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sJ0DH-VKCye"
      },
      "outputs": [],
      "source": [
        "def sobel_edge_detector(image_path, kernel_size=3):\n",
        "    \"\"\"\n",
        "    Apply Sobel edge detection to an image.\n",
        "\n",
        "    Args:\n",
        "    - image_path (str): Path to the input image.\n",
        "    - kernel_size (int): Size of the Gaussian kernel for blurring.\n",
        "\n",
        "    Returns:\n",
        "    - Tuple of (grad_mag, grad_x, grad_y):\n",
        "        - grad_mag (numpy.ndarray): Gradient magnitude image.\n",
        "        - grad_x (numpy.ndarray): Gradient in the x-direction.\n",
        "        - grad_y (numpy.ndarray): Gradient in the y-direction.\n",
        "    \"\"\"\n",
        "    if kernel_size % 2 == 0 or kernel_size <= 1:\n",
        "        raise ValueError(\"Kernel size must be odd and greater than 1.\")\n",
        "\n",
        "    # Read the image from the specified path\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(\n",
        "            f\"The specified image path does not exist: {image_path}\"\n",
        "        )\n",
        "\n",
        "    # Convert the image to grayscale for edge detection\n",
        "    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian blur to smooth the image and reduce noise,\n",
        "    # which helps in the edge detection process\n",
        "    blurred_image = cv2.GaussianBlur(gray_image, (kernel_size, kernel_size), 0)\n",
        "\n",
        "    # Define Sobel kernels for x and y directions\n",
        "    kernel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
        "    kernel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
        "\n",
        "    # Apply convolution with the Sobel kernels to detect edges in x and y directions\n",
        "    grad_x = cv2.filter2D(blurred_image, cv2.CV_64F, kernel_x)\n",
        "    grad_y = cv2.filter2D(blurred_image, cv2.CV_64F, kernel_y)\n",
        "\n",
        "    # Calculate the gradient magnitude as the Euclidean norm of gradients in x and y directions\n",
        "    grad_mag = np.sqrt(grad_x**2 + grad_y**2)\n",
        "\n",
        "    # Convert gradient magnitude to 8-bit unsigned integer type for displaying\n",
        "    # grad_mag_uint8 = np.array(grad_mag, dtype=np.uint8)\n",
        "    grad_mag_uint8 = cv2.convertScaleAbs(grad_mag)\n",
        "\n",
        "    return grad_mag_uint8, grad_x, grad_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the function and display the result\n",
        "sobel_img, x, y = sobel_edge_detector(png_img_list[0], kernel_size=3)\n",
        "\n",
        "# Displaying the Sobel edge detection result\n",
        "plt.figure(figsize=(4, 3))\n",
        "plt.imshow(sobel_img, cmap=\"gray\")\n",
        "plt.axis(\"off\")  # Hides the axis\n",
        "plt.title(\"Sobel Edge Detection Result\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo6I7zSuC-B_"
      },
      "source": [
        "# Canny Edge Detector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDmVblsqSGhx"
      },
      "outputs": [],
      "source": [
        "def non_maximum_suppression(gradient_magnitude, gradient_direction):\n",
        "    rows, cols = gradient_magnitude.shape\n",
        "    suppressed = np.zeros_like(gradient_magnitude)\n",
        "    angle = gradient_direction * 180.0 / np.pi\n",
        "    angle[angle < 0] += 180\n",
        "\n",
        "    for i in range(1, rows - 1):\n",
        "        for j in range(1, cols - 1):\n",
        "            q = 255\n",
        "            r = 255\n",
        "\n",
        "            # East-West (0 degrees)\n",
        "            if (0 <= angle[i, j] < 22.5) or (157.5 <= angle[i, j] <= 180):\n",
        "                q = gradient_magnitude[i, j + 1]\n",
        "                r = gradient_magnitude[i, j - 1]\n",
        "            # Northeast-Southwest (45 degrees)\n",
        "            elif 22.5 <= angle[i, j] < 67.5:\n",
        "                q = gradient_magnitude[i + 1, j - 1]\n",
        "                r = gradient_magnitude[i - 1, j + 1]\n",
        "            # North-South (90 degrees)\n",
        "            elif 67.5 <= angle[i, j] < 112.5:\n",
        "                q = gradient_magnitude[i + 1, j]\n",
        "                r = gradient_magnitude[i - 1, j]\n",
        "            # Northwest-Southeast (135 degrees)\n",
        "            elif 112.5 <= angle[i, j] < 157.5:\n",
        "                q = gradient_magnitude[i - 1, j - 1]\n",
        "                r = gradient_magnitude[i + 1, j + 1]\n",
        "\n",
        "            if (gradient_magnitude[i, j] >= q) and (gradient_magnitude[i, j] >= r):\n",
        "                suppressed[i, j] = gradient_magnitude[i, j]\n",
        "            else:\n",
        "                suppressed[i, j] = 0\n",
        "\n",
        "    return suppressed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtvySssXSJuz"
      },
      "outputs": [],
      "source": [
        "def double_threshold(image, low_threshold, high_threshold):\n",
        "    high_threshold = image.max() * high_threshold\n",
        "    low_threshold = high_threshold * low_threshold\n",
        "\n",
        "    rows, cols = image.shape\n",
        "    result = np.zeros((rows, cols), dtype=np.int32)\n",
        "\n",
        "    weak = np.int32(25)\n",
        "    strong = np.int32(255)\n",
        "\n",
        "    strong_i, strong_j = np.where(image >= high_threshold)\n",
        "    zeros_i, zeros_j = np.where(image < low_threshold)\n",
        "\n",
        "    weak_i, weak_j = np.where((image <= high_threshold) & (image >= low_threshold))\n",
        "\n",
        "    result[strong_i, strong_j] = strong\n",
        "    result[weak_i, weak_j] = weak\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3J9-B5JPSLDl"
      },
      "outputs": [],
      "source": [
        "def edge_tracking(image):\n",
        "    weak = 25\n",
        "    strong = 255\n",
        "\n",
        "    rows, cols = image.shape\n",
        "\n",
        "    for i in range(1, rows - 1):\n",
        "        for j in range(1, cols - 1):\n",
        "            if image[i, j] == weak:\n",
        "                if np.any(image[i - 1 : i + 2, j - 1 : j + 2] == strong) or np.any(\n",
        "                    image[i - 1 : i + 2, j - 1 : j + 2] == strong\n",
        "                ):\n",
        "                    image[i, j] = strong\n",
        "                else:\n",
        "                    image[i, j] = 0\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuZ_CSxiSMiS"
      },
      "outputs": [],
      "source": [
        "def canny_edge_detector(image_path, kernel_size, low_threshold, high_threshold):\n",
        "    # Compute Sobel gradients\n",
        "    gradient_mag, sobelx, sobely = sobel_edge_detector(image_path)\n",
        "    gradient_dir = np.arctan2(sobely, sobelx)\n",
        "\n",
        "    # Non-maximum suppression\n",
        "    suppressed = non_maximum_suppression(gradient_mag, gradient_dir)\n",
        "\n",
        "    # Double thresholding\n",
        "    thresholded = double_threshold(suppressed, low_threshold, high_threshold)\n",
        "\n",
        "    # Edge tracking by hysteresis\n",
        "    edges = edge_tracking(thresholded)\n",
        "\n",
        "    return edges.astype(\"uint8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "0_ntWrIrC6nJ",
        "outputId": "6bb7dca9-d6dd-4bf9-e981-a50b7c1905b3"
      },
      "outputs": [],
      "source": [
        "# Path to the input image\n",
        "image_path = png_img_list[0]\n",
        "\n",
        "# Perform Canny edge detection\n",
        "canny_edges = canny_edge_detector(\n",
        "    image_path, kernel_size=5, low_threshold=0.1, high_threshold=0.5\n",
        ")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))  # Change the size as needed\n",
        "\n",
        "# Display the image\n",
        "ax.imshow(canny_edges, cmap=\"gray\")\n",
        "ax.axis(\"off\")  # Turn off axis\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxkaqXN9DC0n"
      },
      "source": [
        "# Utilize Hough Transform With Canny & Sobel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MezshkLR-Am3"
      },
      "outputs": [],
      "source": [
        "def my_hough_lines(image, rho_resolution, theta_resolution, threshold):\n",
        "    # Extract the height and width of the image\n",
        "    height, width = image.shape\n",
        "\n",
        "    # Define the maximum possible distance in the image (diagonal)\n",
        "    max_rho = int(np.ceil(np.sqrt(height**2 + width**2)))\n",
        "\n",
        "    # Define the range of theta from 0 to 180 degrees\n",
        "    thetas = np.linspace(0, np.pi, int(np.round(np.pi / theta_resolution)))\n",
        "\n",
        "    # Initialize the accumulator array\n",
        "    accumulator = np.zeros((2 * max_rho, len(thetas)), dtype=np.uint64)\n",
        "\n",
        "    # Find the indices of edge pixels in the image\n",
        "    edge_indices = np.argwhere(image > 0)\n",
        "\n",
        "    # Iterate over each edge pixel\n",
        "    for y, x in edge_indices:\n",
        "        # Iterate over each theta value\n",
        "        for theta_index, theta in enumerate(thetas):\n",
        "            # Calculate rho for the given theta\n",
        "            rho = int(np.round(x * np.cos(theta) + y * np.sin(theta)))\n",
        "            # Increment the corresponding accumulator cell\n",
        "            accumulator[rho + max_rho, theta_index] += 1\n",
        "\n",
        "    # Find the indices of cells with votes above the threshold\n",
        "    rho_indices, theta_indices = np.where(accumulator >= threshold)\n",
        "\n",
        "    # Extract the rho and theta values from the indices\n",
        "    rhos = rho_indices - max_rho\n",
        "    thetas = thetas[theta_indices]\n",
        "\n",
        "    # Return the detected lines as (rho, theta) pairs\n",
        "    return list(zip(rhos, thetas))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fl4vemHicYYy"
      },
      "outputs": [],
      "source": [
        "def hough_transform(img_name, method=\"Canny\"):\n",
        "    # Read the input image\n",
        "    image = cv2.imread(img_name)\n",
        "\n",
        "    # Convert BGR to RGB\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Perform edge detection using the Canny edge detector\n",
        "    if method == \"Canny\":\n",
        "        edges = canny_edge_detector(img_name, 5, 50, 150)\n",
        "    else:\n",
        "        edges, _, _ = sobel_edge_detector(img_name, kernel_size=5)\n",
        "\n",
        "    lines = my_hough_lines(edges, 1, np.pi / 180, 150)\n",
        "\n",
        "    x_lines = [0, image.shape[0]]\n",
        "    y_lines = [0, image.shape[1]]\n",
        "\n",
        "    try:\n",
        "        for rho, theta in lines[:, 0]:\n",
        "            a = np.cos(theta)\n",
        "            b = np.sin(theta)\n",
        "            x0 = a * rho\n",
        "            y0 = b * rho\n",
        "            x1 = int(x0 + 1000 * (-b))\n",
        "            y1 = int(y0 + 1000 * (a))\n",
        "            x2 = int(x0 - 1000 * (-b))\n",
        "            y2 = int(y0 - 1000 * (a))\n",
        "            cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 4)\n",
        "            if x1 < 0 and x2 > image.shape[0]:\n",
        "                y_lines.append((y1 + y2) // 2)\n",
        "\n",
        "            elif y1 < 0 and y2 > image.shape[1]:\n",
        "                x_lines.append((x1 + x2) // 2)\n",
        "\n",
        "        x1, y1, x2, y2 = xml_coordinates[img_name]\n",
        "\n",
        "        box_image = cv2.imread(img_name)\n",
        "        box_image = cv2.cvtColor(box_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Create a figure with two subplots\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(12, 6))\n",
        "        # Display extracted edges\n",
        "        axes[0].imshow(edges, cmap=\"gray\")\n",
        "        axes[0].set_title(\"Edge Extracted\")\n",
        "        axes[0].axis(\"off\")\n",
        "\n",
        "        # Display Hough lines\n",
        "        axes[1].imshow(image)\n",
        "        axes[1].set_title(\"Hough Lines\")\n",
        "        axes[1].axis(\"off\")\n",
        "\n",
        "        # Display Boundary Boxes\n",
        "        axes[2].imshow(box_image)\n",
        "        axes[2].set_title(\"Boundary Boxes\")\n",
        "        axes[2].axis(\"off\")\n",
        "\n",
        "    except TypeError:\n",
        "        pass\n",
        "    finally:\n",
        "        x_lines = sorted(x_lines)\n",
        "        y_lines = sorted(y_lines)\n",
        "\n",
        "        return x_lines, y_lines, xml_coordinates[img_name]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTIiB1uNgRUb"
      },
      "source": [
        "# Predict Plate Boundaries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzsV-SF7gQ6R"
      },
      "outputs": [],
      "source": [
        "def predict_plate(img_name, method=\"Canny\"):\n",
        "    # Read the input image\n",
        "    image = cv2.imread(img_name)\n",
        "\n",
        "    # Convert BGR image to RGB\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    x_lines, y_lines, real_coordinates = hough_transform(img_name, method)\n",
        "    x_top = 0\n",
        "    x_bottom = 10000\n",
        "\n",
        "    y_top = 0\n",
        "    y_bottom = 10000\n",
        "\n",
        "    if len(x_lines) < 4:\n",
        "        x_top = x_lines[0]\n",
        "        x_bottom = x_lines[-1]\n",
        "\n",
        "    else:\n",
        "        x_top = x_lines[1]\n",
        "        x_bottom = x_lines[-2]\n",
        "\n",
        "    if len(y_lines) < 4:\n",
        "        y_top = y_lines[0]\n",
        "        y_bottom = y_lines[-1]\n",
        "\n",
        "    else:\n",
        "        y_top = y_lines[1]\n",
        "        y_bottom = y_lines[-2]\n",
        "\n",
        "    # Create a figure with two subplots\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    # Display extracted edges\n",
        "    axes[0].imshow(image)\n",
        "    axes[0].set_title(\"Original Image\")\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    # Draw the vertical line\n",
        "    plt.axvline(x=x_top, color=\"red\")\n",
        "    plt.axvline(x=x_bottom, color=\"red\")\n",
        "\n",
        "    # Draw the vertical line\n",
        "    plt.axhline(y=y_top, color=\"red\")\n",
        "    plt.axhline(y=y_bottom, color=\"red\")\n",
        "\n",
        "    # Fill the area inside the box\n",
        "    plt.fill_betweenx([y_top, y_bottom], x_top, x_bottom, color=\"red\", alpha=0.5)\n",
        "\n",
        "    x1, y1, x2, y2 = real_coordinates\n",
        "\n",
        "    # Calculate coordinates for the intersection rectangle\n",
        "    x_intersection_top = max(x_top, x1)\n",
        "    y_intersection_top = max(y_top, y1)\n",
        "    x_intersection_bottom = min(x_bottom, x2)\n",
        "    y_intersection_bottom = min(y_bottom, y2)\n",
        "\n",
        "    # Calculate coordinates for the union rectangle\n",
        "    x_union_top = min(x_top, x1)\n",
        "    y_union_top = min(y_top, y1)\n",
        "    x_union_bottom = max(x_bottom, x2)\n",
        "    y_union_bottom = max(y_bottom, y2)\n",
        "\n",
        "    # Draw the first rectangle\n",
        "    plt.plot(\n",
        "        [x_top, x_bottom, x_bottom, x_top, x_top],\n",
        "        [y_top, y_top, y_bottom, y_bottom, y_top],\n",
        "        color=\"blue\",\n",
        "    )\n",
        "\n",
        "    # Draw the second rectangle\n",
        "    plt.plot([x1, x2, x2, x1, x1], [y1, y1, y2, y2, y1], color=\"green\")\n",
        "\n",
        "    # Draw the intersection rectangle\n",
        "    plt.fill_betweenx(\n",
        "        [y_intersection_top, y_intersection_bottom],\n",
        "        x_intersection_top,\n",
        "        x_intersection_bottom,\n",
        "        color=\"black\",\n",
        "        alpha=0.9,\n",
        "    )\n",
        "\n",
        "    # Draw the union rectangle\n",
        "    plt.fill_betweenx(\n",
        "        [y_union_top, y_union_bottom],\n",
        "        x_union_top,\n",
        "        x_union_bottom,\n",
        "        color=\"yellow\",\n",
        "        alpha=0.3,\n",
        "    )\n",
        "\n",
        "    # Display extracted edges\n",
        "    axes[1].imshow(image)\n",
        "    axes[1].set_title(\"Boxes\")\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "    # Show the image with the vertical line\n",
        "    plt.show()\n",
        "\n",
        "    # Calculate areas of the rectangles and the intersection\n",
        "    area_rect1 = (x_bottom - x_top) * (y_bottom - y_top)\n",
        "    area_rect2 = (x2 - x1) * (y2 - y1)\n",
        "    area_intersection = max(0, x_intersection_bottom - x_intersection_top) * max(\n",
        "        0, y_intersection_bottom - y_intersection_top\n",
        "    )\n",
        "\n",
        "    # Calculate area of the union\n",
        "    area_union = area_rect1 + area_rect2 - area_intersection\n",
        "\n",
        "    # Calculate Intersection over Union (IoU)\n",
        "    iou = area_intersection / area_union\n",
        "\n",
        "    return iou"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm5LzpnwP83b"
      },
      "source": [
        "# Calculate Overall Prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vSF64VpeTAxF",
        "outputId": "ffb24fe0-241c-4ef5-9c75-61b8f7a2b440"
      },
      "outputs": [],
      "source": [
        "canny_iou_values = list()\n",
        "\n",
        "for image in png_img_list:\n",
        "    iou = predict_plate(image, method=\"Canny\")\n",
        "    canny_iou_values.append(iou)\n",
        "    print(\"Intersection over Union (IoU):\", iou)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zZV5g4vQUBQ",
        "outputId": "f8730e33-0a09-47b6-c13e-9bf7b404efb1"
      },
      "outputs": [],
      "source": [
        "print(\"Canny IoU Average : \", sum(canny_iou_values) / len(canny_iou_values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AdP_v5lcfiyO",
        "outputId": "dbd6a338-dafe-4cd0-f67f-0e3b1f9db509"
      },
      "outputs": [],
      "source": [
        "sobel_iou_values = list()\n",
        "\n",
        "for image in png_img_list:\n",
        "    iou = predict_plate(image, method=\"Sobel\")\n",
        "    sobel_iou_values.append(iou)\n",
        "    print(\"Intersection over Union (IoU):\", iou)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVFKGPhqh5kh",
        "outputId": "2d72aa4c-9c35-4399-fb70-4559ca65654d"
      },
      "outputs": [],
      "source": [
        "print(\"Sobel IoU Average  : \", sum(sobel_iou_values) / len(sobel_iou_values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "73VFxqCI73QE",
        "outputId": "65b35fb5-9562-49df-e6d0-5f8549d80941"
      },
      "outputs": [],
      "source": [
        "iou = predict_plate(png_img_list[0], method=\"Sobel\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
