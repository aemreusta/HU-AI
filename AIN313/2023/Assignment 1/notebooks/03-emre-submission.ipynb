{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ahmet Emre Usta - b2200765036\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import (\n",
    "    MinMaxScaler,\n",
    "    LabelEncoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = \"/Users/emre/GitHub/HU-AI/AIN313/Assignment 1\"\n",
    "DATASET_PATH = os.path.join(working_dir, \"dataset\")\n",
    "RAW_DATASET_PATH = os.path.join(DATASET_PATH, \"raw\")\n",
    "ANIMES_PATH = os.path.join(RAW_DATASET_PATH, \"animes.csv\")\n",
    "USER_RATES_TRAIN_PATH = os.path.join(RAW_DATASET_PATH, \"user_rates_train.csv\")\n",
    "USER_RATES_TEST_PATH = os.path.join(RAW_DATASET_PATH, \"user_rates_test.csv\")\n",
    "PROCESSED_DATASET_PATH = os.path.join(DATASET_PATH, \"processed\")\n",
    "TRAIN_PATH = os.path.join(PROCESSED_DATASET_PATH, \"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert duration to minutes\n",
    "def convert_to_minutes(duration_str):\n",
    "    parts = duration_str.split()\n",
    "    total_minutes = 0\n",
    "    # print(parts)\n",
    "\n",
    "    for idx, part in enumerate(parts):\n",
    "        if \"hr\" == part:\n",
    "            total_minutes += int(parts[idx - 1]) * 60\n",
    "\n",
    "        elif \"min\" == part:\n",
    "            total_minutes += int(parts[idx - 1])\n",
    "\n",
    "    # print(total_minutes)\n",
    "    return total_minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Datasets and Show Info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_animes = pd.read_csv(ANIMES_PATH)\n",
    "df_user_rates_train = pd.read_csv(USER_RATES_TRAIN_PATH)\n",
    "df_user_rates_test = pd.read_csv(USER_RATES_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animes Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Type</th>\n",
       "      <th>Studios</th>\n",
       "      <th>Source</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>Action, Award Winning, Sci-Fi</td>\n",
       "      <td>TV</td>\n",
       "      <td>Sunrise</td>\n",
       "      <td>Original</td>\n",
       "      <td>24 min per ep</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/4/196...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Cowboy Bebop: Tengoku no Tobira</td>\n",
       "      <td>Action, Sci-Fi</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Bones</td>\n",
       "      <td>Original</td>\n",
       "      <td>1 hr 55 min</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/1439/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Trigun</td>\n",
       "      <td>Action, Adventure, Sci-Fi</td>\n",
       "      <td>TV</td>\n",
       "      <td>Madhouse</td>\n",
       "      <td>Manga</td>\n",
       "      <td>24 min per ep</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/7/203...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Witch Hunter Robin</td>\n",
       "      <td>Action, Drama, Mystery, Supernatural</td>\n",
       "      <td>TV</td>\n",
       "      <td>Sunrise</td>\n",
       "      <td>Original</td>\n",
       "      <td>25 min per ep</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/10/19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Bouken Ou Beet</td>\n",
       "      <td>Adventure, Fantasy, Supernatural</td>\n",
       "      <td>TV</td>\n",
       "      <td>Toei Animation</td>\n",
       "      <td>Manga</td>\n",
       "      <td>23 min per ep</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/7/215...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anime_id                             Name  \\\n",
       "0         1                     Cowboy Bebop   \n",
       "1         5  Cowboy Bebop: Tengoku no Tobira   \n",
       "2         6                           Trigun   \n",
       "3         7               Witch Hunter Robin   \n",
       "4         8                   Bouken Ou Beet   \n",
       "\n",
       "                                 Genres   Type         Studios    Source  \\\n",
       "0         Action, Award Winning, Sci-Fi     TV         Sunrise  Original   \n",
       "1                        Action, Sci-Fi  Movie           Bones  Original   \n",
       "2             Action, Adventure, Sci-Fi     TV        Madhouse     Manga   \n",
       "3  Action, Drama, Mystery, Supernatural     TV         Sunrise  Original   \n",
       "4      Adventure, Fantasy, Supernatural     TV  Toei Animation     Manga   \n",
       "\n",
       "        Duration                                          Image URL  \n",
       "0  24 min per ep  https://cdn.myanimelist.net/images/anime/4/196...  \n",
       "1    1 hr 55 min  https://cdn.myanimelist.net/images/anime/1439/...  \n",
       "2  24 min per ep  https://cdn.myanimelist.net/images/anime/7/203...  \n",
       "3  25 min per ep  https://cdn.myanimelist.net/images/anime/10/19...  \n",
       "4  23 min per ep  https://cdn.myanimelist.net/images/anime/7/215...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_animes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24905 entries, 0 to 24904\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   anime_id   24905 non-null  int64 \n",
      " 1   Name       24905 non-null  object\n",
      " 2   Genres     24905 non-null  object\n",
      " 3   Type       24905 non-null  object\n",
      " 4   Studios    24905 non-null  object\n",
      " 5   Source     24905 non-null  object\n",
      " 6   Duration   24905 non-null  object\n",
      " 7   Image URL  24905 non-null  object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_animes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24905"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_animes[\"anime_id\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Rates Train Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Username</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>Anime Title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>549</td>\n",
       "      <td>dotGif</td>\n",
       "      <td>790</td>\n",
       "      <td>Ergo Proxy</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549</td>\n",
       "      <td>dotGif</td>\n",
       "      <td>306</td>\n",
       "      <td>Abenobashi Mahouâ˜†Shoutengai</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>549</td>\n",
       "      <td>dotGif</td>\n",
       "      <td>54</td>\n",
       "      <td>Appleseed (Movie)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>549</td>\n",
       "      <td>dotGif</td>\n",
       "      <td>66</td>\n",
       "      <td>Azumanga Daiou The Animation</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>549</td>\n",
       "      <td>dotGif</td>\n",
       "      <td>28805</td>\n",
       "      <td>Bakemono no Ko</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id Username  anime_id                   Anime Title  rating\n",
       "0      549   dotGif       790                    Ergo Proxy       9\n",
       "1      549   dotGif       306   Abenobashi Mahouâ˜†Shoutengai       8\n",
       "2      549   dotGif        54             Appleseed (Movie)       7\n",
       "3      549   dotGif        66  Azumanga Daiou The Animation       8\n",
       "4      549   dotGif     28805                Bakemono no Ko       9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_rates_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49360 entries, 0 to 49359\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   user_id      49360 non-null  int64 \n",
      " 1   Username     49360 non-null  object\n",
      " 2   anime_id     49360 non-null  int64 \n",
      " 3   Anime Title  49360 non-null  object\n",
      " 4   rating       49360 non-null  int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_user_rates_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_rates_train[\"user_id\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Rates Test Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Username</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>Anime Title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15885</td>\n",
       "      <td>hardcoreBC</td>\n",
       "      <td>2026</td>\n",
       "      <td>Hayate no Gotoku!</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15885</td>\n",
       "      <td>hardcoreBC</td>\n",
       "      <td>120</td>\n",
       "      <td>Fruits Basket</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15885</td>\n",
       "      <td>hardcoreBC</td>\n",
       "      <td>71</td>\n",
       "      <td>Full Metal Panic!</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15885</td>\n",
       "      <td>hardcoreBC</td>\n",
       "      <td>72</td>\n",
       "      <td>Full Metal Panic? Fumoffu</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15885</td>\n",
       "      <td>hardcoreBC</td>\n",
       "      <td>121</td>\n",
       "      <td>Fullmetal Alchemist</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    Username  anime_id                Anime Title  rating\n",
       "0    15885  hardcoreBC      2026          Hayate no Gotoku!       9\n",
       "1    15885  hardcoreBC       120              Fruits Basket      10\n",
       "2    15885  hardcoreBC        71          Full Metal Panic!       9\n",
       "3    15885  hardcoreBC        72  Full Metal Panic? Fumoffu      10\n",
       "4    15885  hardcoreBC       121        Fullmetal Alchemist       9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_rates_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 877 entries, 0 to 876\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   user_id      877 non-null    int64 \n",
      " 1   Username     877 non-null    object\n",
      " 2   anime_id     877 non-null    int64 \n",
      " 3   Anime Title  877 non-null    object\n",
      " 4   rating       877 non-null    int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 34.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_user_rates_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_rates_test[\"user_id\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Username</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>Anime Title</th>\n",
       "      <th>rating</th>\n",
       "      <th>Name</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Type</th>\n",
       "      <th>Studios</th>\n",
       "      <th>Source</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>549</td>\n",
       "      <td>dotGif</td>\n",
       "      <td>790</td>\n",
       "      <td>Ergo Proxy</td>\n",
       "      <td>9</td>\n",
       "      <td>Ergo Proxy</td>\n",
       "      <td>Mystery, Sci-Fi</td>\n",
       "      <td>TV</td>\n",
       "      <td>Manglobe</td>\n",
       "      <td>Original</td>\n",
       "      <td>25 min per ep</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/1183/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3242</td>\n",
       "      <td>KIN_</td>\n",
       "      <td>790</td>\n",
       "      <td>Ergo Proxy</td>\n",
       "      <td>9</td>\n",
       "      <td>Ergo Proxy</td>\n",
       "      <td>Mystery, Sci-Fi</td>\n",
       "      <td>TV</td>\n",
       "      <td>Manglobe</td>\n",
       "      <td>Original</td>\n",
       "      <td>25 min per ep</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/1183/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9377</td>\n",
       "      <td>zaragas</td>\n",
       "      <td>790</td>\n",
       "      <td>Ergo Proxy</td>\n",
       "      <td>10</td>\n",
       "      <td>Ergo Proxy</td>\n",
       "      <td>Mystery, Sci-Fi</td>\n",
       "      <td>TV</td>\n",
       "      <td>Manglobe</td>\n",
       "      <td>Original</td>\n",
       "      <td>25 min per ep</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/1183/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11092</td>\n",
       "      <td>mafia89</td>\n",
       "      <td>790</td>\n",
       "      <td>Ergo Proxy</td>\n",
       "      <td>8</td>\n",
       "      <td>Ergo Proxy</td>\n",
       "      <td>Mystery, Sci-Fi</td>\n",
       "      <td>TV</td>\n",
       "      <td>Manglobe</td>\n",
       "      <td>Original</td>\n",
       "      <td>25 min per ep</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/1183/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13980</td>\n",
       "      <td>xaeonbluex</td>\n",
       "      <td>790</td>\n",
       "      <td>Ergo Proxy</td>\n",
       "      <td>10</td>\n",
       "      <td>Ergo Proxy</td>\n",
       "      <td>Mystery, Sci-Fi</td>\n",
       "      <td>TV</td>\n",
       "      <td>Manglobe</td>\n",
       "      <td>Original</td>\n",
       "      <td>25 min per ep</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/1183/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    Username  anime_id Anime Title  rating        Name  \\\n",
       "0      549      dotGif       790  Ergo Proxy       9  Ergo Proxy   \n",
       "1     3242        KIN_       790  Ergo Proxy       9  Ergo Proxy   \n",
       "2     9377     zaragas       790  Ergo Proxy      10  Ergo Proxy   \n",
       "3    11092     mafia89       790  Ergo Proxy       8  Ergo Proxy   \n",
       "4    13980  xaeonbluex       790  Ergo Proxy      10  Ergo Proxy   \n",
       "\n",
       "            Genres Type   Studios    Source       Duration  \\\n",
       "0  Mystery, Sci-Fi   TV  Manglobe  Original  25 min per ep   \n",
       "1  Mystery, Sci-Fi   TV  Manglobe  Original  25 min per ep   \n",
       "2  Mystery, Sci-Fi   TV  Manglobe  Original  25 min per ep   \n",
       "3  Mystery, Sci-Fi   TV  Manglobe  Original  25 min per ep   \n",
       "4  Mystery, Sci-Fi   TV  Manglobe  Original  25 min per ep   \n",
       "\n",
       "                                           Image URL  \n",
       "0  https://cdn.myanimelist.net/images/anime/1183/...  \n",
       "1  https://cdn.myanimelist.net/images/anime/1183/...  \n",
       "2  https://cdn.myanimelist.net/images/anime/1183/...  \n",
       "3  https://cdn.myanimelist.net/images/anime/1183/...  \n",
       "4  https://cdn.myanimelist.net/images/anime/1183/...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge df_user_rates_train with df_animes using anime_id as the key\n",
    "merged_df = df_user_rates_train.merge(df_animes, on=\"anime_id\", how=\"inner\")\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49360 entries, 0 to 49359\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   user_id      49360 non-null  int64 \n",
      " 1   Username     49360 non-null  object\n",
      " 2   anime_id     49360 non-null  int64 \n",
      " 3   Anime Title  49360 non-null  object\n",
      " 4   rating       49360 non-null  int64 \n",
      " 5   Name         49360 non-null  object\n",
      " 6   Genres       49360 non-null  object\n",
      " 7   Type         49360 non-null  object\n",
      " 8   Studios      49360 non-null  object\n",
      " 9   Source       49360 non-null  object\n",
      " 10  Duration     49360 non-null  object\n",
      " 11  Image URL    49360 non-null  object\n",
      "dtypes: int64(3), object(9)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Username</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>Anime Title</th>\n",
       "      <th>rating</th>\n",
       "      <th>Name</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Type</th>\n",
       "      <th>Studios</th>\n",
       "      <th>Source</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15885</td>\n",
       "      <td>hardcoreBC</td>\n",
       "      <td>2026</td>\n",
       "      <td>Hayate no Gotoku!</td>\n",
       "      <td>9</td>\n",
       "      <td>Hayate no Gotoku!</td>\n",
       "      <td>Action, Comedy, Romance</td>\n",
       "      <td>TV</td>\n",
       "      <td>SynergySP</td>\n",
       "      <td>Manga</td>\n",
       "      <td>24 min per ep</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/7/739...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32511</td>\n",
       "      <td>firangel</td>\n",
       "      <td>2026</td>\n",
       "      <td>Hayate no Gotoku!</td>\n",
       "      <td>7</td>\n",
       "      <td>Hayate no Gotoku!</td>\n",
       "      <td>Action, Comedy, Romance</td>\n",
       "      <td>TV</td>\n",
       "      <td>SynergySP</td>\n",
       "      <td>Manga</td>\n",
       "      <td>24 min per ep</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/7/739...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15885</td>\n",
       "      <td>hardcoreBC</td>\n",
       "      <td>120</td>\n",
       "      <td>Fruits Basket</td>\n",
       "      <td>10</td>\n",
       "      <td>Fruits Basket</td>\n",
       "      <td>Drama, Romance, Supernatural</td>\n",
       "      <td>TV</td>\n",
       "      <td>Studio Deen</td>\n",
       "      <td>Manga</td>\n",
       "      <td>24 min per ep</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/4/752...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>484803</td>\n",
       "      <td>xmidorix</td>\n",
       "      <td>120</td>\n",
       "      <td>Fruits Basket</td>\n",
       "      <td>9</td>\n",
       "      <td>Fruits Basket</td>\n",
       "      <td>Drama, Romance, Supernatural</td>\n",
       "      <td>TV</td>\n",
       "      <td>Studio Deen</td>\n",
       "      <td>Manga</td>\n",
       "      <td>24 min per ep</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/4/752...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>488782</td>\n",
       "      <td>Kotetsu_Kaburagi</td>\n",
       "      <td>120</td>\n",
       "      <td>Fruits Basket</td>\n",
       "      <td>7</td>\n",
       "      <td>Fruits Basket</td>\n",
       "      <td>Drama, Romance, Supernatural</td>\n",
       "      <td>TV</td>\n",
       "      <td>Studio Deen</td>\n",
       "      <td>Manga</td>\n",
       "      <td>24 min per ep</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/4/752...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id          Username  anime_id        Anime Title  rating  \\\n",
       "0    15885        hardcoreBC      2026  Hayate no Gotoku!       9   \n",
       "1    32511          firangel      2026  Hayate no Gotoku!       7   \n",
       "2    15885        hardcoreBC       120      Fruits Basket      10   \n",
       "3   484803          xmidorix       120      Fruits Basket       9   \n",
       "4   488782  Kotetsu_Kaburagi       120      Fruits Basket       7   \n",
       "\n",
       "                Name                        Genres Type      Studios Source  \\\n",
       "0  Hayate no Gotoku!       Action, Comedy, Romance   TV    SynergySP  Manga   \n",
       "1  Hayate no Gotoku!       Action, Comedy, Romance   TV    SynergySP  Manga   \n",
       "2      Fruits Basket  Drama, Romance, Supernatural   TV  Studio Deen  Manga   \n",
       "3      Fruits Basket  Drama, Romance, Supernatural   TV  Studio Deen  Manga   \n",
       "4      Fruits Basket  Drama, Romance, Supernatural   TV  Studio Deen  Manga   \n",
       "\n",
       "        Duration                                          Image URL  \n",
       "0  24 min per ep  https://cdn.myanimelist.net/images/anime/7/739...  \n",
       "1  24 min per ep  https://cdn.myanimelist.net/images/anime/7/739...  \n",
       "2  24 min per ep  https://cdn.myanimelist.net/images/anime/4/752...  \n",
       "3  24 min per ep  https://cdn.myanimelist.net/images/anime/4/752...  \n",
       "4  24 min per ep  https://cdn.myanimelist.net/images/anime/4/752...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge df_user_rates_train with df_animes using anime_id as the key\n",
    "merged_test_df = df_user_rates_test.merge(df_animes, on=\"anime_id\", how=\"inner\")\n",
    "merged_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 877 entries, 0 to 876\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   user_id      877 non-null    int64 \n",
      " 1   Username     877 non-null    object\n",
      " 2   anime_id     877 non-null    int64 \n",
      " 3   Anime Title  877 non-null    object\n",
      " 4   rating       877 non-null    int64 \n",
      " 5   Name         877 non-null    object\n",
      " 6   Genres       877 non-null    object\n",
      " 7   Type         877 non-null    object\n",
      " 8   Studios      877 non-null    object\n",
      " 9   Source       877 non-null    object\n",
      " 10  Duration     877 non-null    object\n",
      " 11  Image URL    877 non-null    object\n",
      "dtypes: int64(3), object(9)\n",
      "memory usage: 82.3+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnecessary_columns = [\"Anime Title\", \"Image URL\", \"Name\", \"Username\"]\n",
    "merged_df.drop(unnecessary_columns, axis=1, inplace=True)\n",
    "merged_test_df.drop(unnecessary_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source -> 17\n",
      "Type -> 6\n",
      "Studios -> 434\n",
      "Genres -> 606\n",
      "Duration -> 201\n"
     ]
    }
   ],
   "source": [
    "nunique_nums = [\"Source\", \"Type\", \"Studios\", \"Genres\", \"Duration\"]\n",
    "\n",
    "for col in nunique_nums:\n",
    "    print(f\"{col} -> {merged_df[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source -> 10\n",
      "Type -> 5\n",
      "Studios -> 104\n",
      "Genres -> 205\n",
      "Duration -> 70\n"
     ]
    }
   ],
   "source": [
    "for col in nunique_nums:\n",
    "    print(f\"{col} -> {merged_test_df[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the comma-separated values in the 'Genres' column and one-hot encode them\n",
    "genre_dummies = merged_df[\"Genres\"].str.get_dummies(sep=\", \")\n",
    "test_genre_dummies = merged_test_df[\"Genres\"].str.get_dummies(sep=\", \")\n",
    "\n",
    "# Concatenate the one-hot encoded genres with the original DataFrame\n",
    "merged_df = pd.concat([merged_df, genre_dummies], axis=1)\n",
    "merged_test_df = pd.concat([merged_test_df, test_genre_dummies], axis=1)\n",
    "\n",
    "# Drop the original 'Genres' column if you no longer need it\n",
    "merged_df = merged_df.drop(\"Genres\", axis=1)\n",
    "merged_test_df = merged_test_df.drop(\"Genres\", axis=1)\n",
    "\n",
    "# One-hot encode the 'Studios' column\n",
    "studio_dummies = merged_df[\"Studios\"].str.get_dummies(sep=\", \")\n",
    "test_studio_dummies = merged_test_df[\"Studios\"].str.get_dummies(sep=\", \")\n",
    "\n",
    "# Concatenate the one-hot encoded studios with the original DataFrame\n",
    "merged_df = pd.concat([merged_df, studio_dummies], axis=1)\n",
    "merged_test_df = pd.concat([merged_test_df, test_studio_dummies], axis=1)\n",
    "\n",
    "# Drop the original 'Studios' column if you no longer need it\n",
    "merged_df = merged_df.drop(\"Studios\", axis=1)\n",
    "merged_test_df = merged_test_df.drop(\"Studios\", axis=1)\n",
    "\n",
    "# One-hot encode the 'Studios' column\n",
    "source_dummies = merged_df[\"Source\"].str.get_dummies(sep=\", \")\n",
    "test_source_dummies = merged_test_df[\"Source\"].str.get_dummies(sep=\", \")\n",
    "\n",
    "# Concatenate the one-hot encoded studios with the original DataFrame\n",
    "merged_df = pd.concat([merged_df, source_dummies], axis=1)\n",
    "merged_test_df = pd.concat([merged_test_df, test_source_dummies], axis=1)\n",
    "\n",
    "# Drop the original 'Studios' column if you no longer need it\n",
    "merged_df = merged_df.drop(\"Source\", axis=1)\n",
    "merged_test_df = merged_test_df.drop(\"Source\", axis=1)\n",
    "\n",
    "# One-hot encode the 'Studios' column\n",
    "type_dummies = merged_df[\"Type\"].str.get_dummies(sep=\", \")\n",
    "test_type_dummies = merged_test_df[\"Type\"].str.get_dummies(sep=\", \")\n",
    "\n",
    "# Concatenate the one-hot encoded studios with the original DataFrame\n",
    "merged_df = pd.concat([merged_df, type_dummies], axis=1)\n",
    "merged_test_df = pd.concat([merged_test_df, test_type_dummies], axis=1)\n",
    "\n",
    "# Drop the original 'Studios' column if you no longer need it\n",
    "merged_df = merged_df.drop(\"Type\", axis=1)\n",
    "merged_test_df = merged_test_df.drop(\"Type\", axis=1)\n",
    "\n",
    "# Apply the conversion function to the 'Duration' column\n",
    "merged_df[\"Duration\"] = merged_df[\"Duration\"].apply(convert_to_minutes)\n",
    "merged_test_df[\"Duration\"] = merged_test_df[\"Duration\"].apply(convert_to_minutes)\n",
    "\n",
    "# Min-max scale the 'Duration' column\n",
    "duration_scaler = MinMaxScaler()\n",
    "merged_df[\"Duration\"] = duration_scaler.fit_transform(merged_df[[\"Duration\"]])\n",
    "merged_test_df[\"Duration\"] = duration_scaler.fit_transform(merged_test_df[[\"Duration\"]])\n",
    "\n",
    "rating_scaler = MinMaxScaler()\n",
    "merged_df[\"rating\"] = rating_scaler.fit_transform(merged_df[[\"rating\"]])\n",
    "merged_test_df[\"rating\"] = rating_scaler.fit_transform(merged_test_df[[\"rating\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2999\n",
      "49\n",
      "3293\n",
      "461\n"
     ]
    }
   ],
   "source": [
    "user_id_encoder = LabelEncoder()\n",
    "merged_df[\"user_id\"] = user_id_encoder.fit_transform(merged_df[\"user_id\"])\n",
    "merged_test_df[\"user_id\"] = user_id_encoder.fit_transform(merged_test_df[\"user_id\"])\n",
    "\n",
    "anime_id_encoder = LabelEncoder()\n",
    "merged_df[\"anime_id\"] = anime_id_encoder.fit_transform(merged_df[\"anime_id\"])\n",
    "merged_test_df[\"anime_id\"] = anime_id_encoder.fit_transform(merged_test_df[\"anime_id\"])\n",
    "\n",
    "print(merged_df[\"user_id\"].max())\n",
    "print(merged_test_df[\"user_id\"].max())\n",
    "print(merged_df[\"anime_id\"].max())\n",
    "print(merged_test_df[\"anime_id\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49360 entries, 0 to 49359\n",
      "Columns: 372 entries, user_id to TV\n",
      "dtypes: float64(2), int64(370)\n",
      "memory usage: 140.1 MB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 877 entries, 0 to 876\n",
      "Columns: 130 entries, user_id to TV\n",
      "dtypes: float64(2), int64(128)\n",
      "memory usage: 890.8 KB\n"
     ]
    }
   ],
   "source": [
    "merged_test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Avant Garde</th>\n",
       "      <th>Award Winning</th>\n",
       "      <th>Boys Love</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>...</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Visual novel</th>\n",
       "      <th>Web manga</th>\n",
       "      <th>Web novel</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Music</th>\n",
       "      <th>ONA</th>\n",
       "      <th>OVA</th>\n",
       "      <th>Special</th>\n",
       "      <th>TV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>581</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.14881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>581</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.14881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>581</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.14881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>581</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.14881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>581</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.14881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 372 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  anime_id    rating  Duration  Action  Adventure  Avant Garde  \\\n",
       "0        0       581  0.888889   0.14881       0          0            0   \n",
       "1       10       581  0.888889   0.14881       0          0            0   \n",
       "2       47       581  1.000000   0.14881       0          0            0   \n",
       "3       66       581  0.777778   0.14881       0          0            0   \n",
       "4       82       581  1.000000   0.14881       0          0            0   \n",
       "\n",
       "   Award Winning  Boys Love  Comedy  ...  Unknown  Visual novel  Web manga  \\\n",
       "0              0          0       0  ...        0             0          0   \n",
       "1              0          0       0  ...        0             0          0   \n",
       "2              0          0       0  ...        0             0          0   \n",
       "3              0          0       0  ...        0             0          0   \n",
       "4              0          0       0  ...        0             0          0   \n",
       "\n",
       "   Web novel  Movie  Music  ONA  OVA  Special  TV  \n",
       "0          0      0      0    0    0        0   1  \n",
       "1          0      0      0    0    0        0   1  \n",
       "2          0      0      0    0    0        0   1  \n",
       "3          0      0      0    0    0        0   1  \n",
       "4          0      0      0    0    0        0   1  \n",
       "\n",
       "[5 rows x 372 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Avant Garde</th>\n",
       "      <th>Award Winning</th>\n",
       "      <th>Boys Love</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>...</th>\n",
       "      <th>Original</th>\n",
       "      <th>Other</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Visual novel</th>\n",
       "      <th>Web manga</th>\n",
       "      <th>Movie</th>\n",
       "      <th>ONA</th>\n",
       "      <th>OVA</th>\n",
       "      <th>Special</th>\n",
       "      <th>TV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>247</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.14375</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>247</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.14375</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.14375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.14375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>42</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.14375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  anime_id    rating  Duration  Action  Adventure  Avant Garde  \\\n",
       "0        0       247  0.888889   0.14375       1          0            0   \n",
       "1        2       247  0.666667   0.14375       1          0            0   \n",
       "2        0        42  1.000000   0.14375       0          0            0   \n",
       "3       36        42  0.888889   0.14375       0          0            0   \n",
       "4       38        42  0.666667   0.14375       0          0            0   \n",
       "\n",
       "   Award Winning  Boys Love  Comedy  ...  Original  Other  Unknown  \\\n",
       "0              0          0       1  ...         0      0        0   \n",
       "1              0          0       1  ...         0      0        0   \n",
       "2              0          0       0  ...         0      0        0   \n",
       "3              0          0       0  ...         0      0        0   \n",
       "4              0          0       0  ...         0      0        0   \n",
       "\n",
       "   Visual novel  Web manga  Movie  ONA  OVA  Special  TV  \n",
       "0             0          0      0    0    0        0   1  \n",
       "1             0          0      0    0    0        0   1  \n",
       "2             0          0      0    0    0        0   1  \n",
       "3             0          0      0    0    0        0   1  \n",
       "4             0          0      0    0    0        0   1  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241 ['Hentai', 'A-Line', 'AIC Build', 'AT-2', 'AXsiZ', 'Academy Productions', 'Ajia-do', 'Amarcord', 'Anima', 'Animation 21', 'Animation Do', 'Animation Planet', 'Anime Antenna Iinkai', 'Anpro', 'Arcs Create', 'Artmic', 'Arvo Animation', 'Asahi Production', 'Aubec', 'B.CMAY PICTURES', 'Bandai Namco Pictures', 'Bandai Visual', 'Barnum Studio', 'BeSTACK', 'Beat Frog', 'Bee Media', 'Bibury Animation Studios', 'Big Wing', 'Blue Cat', 'C-Station', 'C2C', 'Cafe de Jeilhouse', 'Chaos Project', 'ChuChu', 'CloverWorks', 'Collaboration Works', 'Colored Pencil Animation', 'Creators in Pack', 'CyberConnect2', 'D.A.S.T.', 'DLE', 'Darts', 'Datama Film', 'Digital Frontier', 'DiomedÃ©a', 'Dongwoo A&E', 'Dream Entertainment', 'E&G Films', 'EMT Squared', 'ENGI', 'Echoes', 'Egg Firm', 'Eiken', 'Encourage Films', 'Fanworks', 'Felix Film', 'Filmlink International', 'Flavors Soft', 'Front Line', 'G-Lam', 'GANSIS', 'GARDEN LODGE', 'GEMBA', 'Gaina', 'Gathering', 'Ginga Ya', 'Grouper Productions', 'HMCH', 'HORNETS', 'Haoliners Animation League', 'Heewon Entertainment', 'Himajin Planning', 'Hoods Drifters Studio', 'Horannabi', 'Hotline', 'I was a Ballerina', 'I-move', 'I.Gzwei', 'ILCA', 'Idol', 'Image House', 'Imagica', 'Inc.', 'Ishimori Entertainment', 'Issen', 'JCF', 'Jinnis Animation Studios', 'K-Factory', 'KSS', 'Kachidoki Studio', 'Kamikaze Douga', 'Kanaban Graphics', 'Kaname Productions', 'Kantou Douga Kai', 'Karaku', 'Kent House', 'KeyEast', 'Kinema Citrus', 'Kino Production', 'Kitty Film Mitaka Studio', 'Knack Productions', 'LIDENFILMS', 'Larx Entertainment', 'Lay-duce', 'Lerche', 'Life Work', 'M.S.C', 'MAPPA', 'Maboroshi Koubou', 'Magic Bus', 'Maho Film', 'Majin', 'Marine Entertainment', 'Marone', 'Marvy Jack', 'Marza Animation Planet', 'Millepensee', 'Minami Machi Bugyousho', 'Mippei Eigeki Kiryuukan', 'Momoi Planning', 'Mouse', 'Mushi Production', 'NAZ', 'NHK Enterprises', 'Nihikime no Dozeu', 'Nut', 'OLM Digital', 'ORADA COMPANY', 'Office No. 8', 'Office Take Off', 'Office Takeout', 'Oh! Production', 'Okuruto Noboru', 'Orange', 'Ordet', 'Oxybot', 'P.I.C.S.', 'PINE JAM', 'PP Project', 'PPM', 'Panda Factory', 'Passione', 'Pastel', 'Peak Hunt', 'Phoenix Entertainment', 'Picture Magic', 'Planet', 'Platinum Vision', 'Plum', 'PoRO', 'Polygon Pictures', 'PrimeTime', 'Production IMS', 'Production Reed', 'Project No.9', 'Purple Cow Studio Japan', 'Qualia Animation', 'REALTHING', 'Remic', 'Revoroot', 'Rikuentai', 'Ripple Film', 'SANZIGEN', 'SIDO LIMITED', 'Schoolzone', 'Science SARU', 'Seven Arcs Pictures', 'Shogakukan Music & Digital Entertainment', 'Shuka', 'Shura', 'Signal.MD', 'Silver', 'Sovat Theater', 'Square Pictures', 'Studio 1st', 'Studio 3Hz', 'Studio 9 Maiami', 'Studio Bind', 'Studio Blanc.', 'Studio Boogie Nights', 'Studio Chizu', 'Studio Dadashow', 'Studio Egg', 'Studio Eromatick', 'Studio Flad', 'Studio Flag', 'Studio G-1Neo', 'Studio Jam', 'Studio Junio', 'Studio Kai', 'Studio Kikan', 'Studio Matrix', 'Studio Mir', 'Studio OX', 'Studio Palette', 'Studio Pastoral', 'Studio Rikka', 'Studio Sign', 'Studio Signpost', 'Studio Soul', 'Studio Ten', 'Studio VOLN', 'Sugar Boy', 'Sunwoo Entertainment', 'Suzuki Mirano', 'Synergy Japan', 'T-Rex', 'TROYCA', 'Telescreen', 'Tezuka Productions', 'The Answer Studio', 'Tomason', 'Trans Arts', 'Tri-Slash', 'Trigger', 'Trinet Entertainment', 'Triple X', 'Twilight Town', 'Urban Product', 'Vega Entertainment', 'Venet', 'Visual 80', 'WAO World', 'XEBEC M2', 'Y.O.U.C', 'Yamamura Animation', 'Yamato Works', 'Yaoyorozu', 'Yokohama Animation Lab', 'Zyc', 'domerica', 'ixtl', 'studio MOTHER', 'Book', 'Card game', 'Mixed media', 'Music', 'Picture book', 'Radio', 'Web novel', 'Music']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n",
      "/var/folders/hs/7w96q1ln53d4q68gvt_vn2wr0000gn/T/ipykernel_1384/3745410248.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_test_df[missing_columns] = 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Avant Garde</th>\n",
       "      <th>Award Winning</th>\n",
       "      <th>Boys Love</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>...</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Visual novel</th>\n",
       "      <th>Web manga</th>\n",
       "      <th>Web novel</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Music</th>\n",
       "      <th>ONA</th>\n",
       "      <th>OVA</th>\n",
       "      <th>Special</th>\n",
       "      <th>TV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>247</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.14375</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>247</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.14375</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.14375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.14375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>42</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.14375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 372 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  anime_id    rating  Duration  Action  Adventure  Avant Garde  \\\n",
       "0        0       247  0.888889   0.14375       1          0            0   \n",
       "1        2       247  0.666667   0.14375       1          0            0   \n",
       "2        0        42  1.000000   0.14375       0          0            0   \n",
       "3       36        42  0.888889   0.14375       0          0            0   \n",
       "4       38        42  0.666667   0.14375       0          0            0   \n",
       "\n",
       "   Award Winning  Boys Love  Comedy  ...  Unknown  Visual novel  Web manga  \\\n",
       "0              0          0       1  ...        0             0          0   \n",
       "1              0          0       1  ...        0             0          0   \n",
       "2              0          0       0  ...        0             0          0   \n",
       "3              0          0       0  ...        0             0          0   \n",
       "4              0          0       0  ...        0             0          0   \n",
       "\n",
       "   Web novel  Movie  Music  ONA  OVA  Special  TV  \n",
       "0          0      0      0    0    0        0   1  \n",
       "1          0      0      0    0    0        0   1  \n",
       "2          0      0      0    0    0        0   1  \n",
       "3          0      0      0    0    0        0   1  \n",
       "4          0      0      0    0    0        0   1  \n",
       "\n",
       "[5 rows x 372 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify missing columns in merged_test_df\n",
    "missing_columns = [\n",
    "    col for col in merged_df.columns if col not in merged_test_df.columns\n",
    "]\n",
    "\n",
    "# Add missing columns to merged_test_df with all values set to 0 (or any other default value)\n",
    "merged_test_df[missing_columns] = 0\n",
    "\n",
    "# Ensure the order of column in the test set is in the same order than in train set\n",
    "merged_test_df = merged_test_df[merged_df.columns]\n",
    "merged_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 877 entries, 0 to 876\n",
      "Columns: 372 entries, user_id to TV\n",
      "dtypes: float64(2), int16(2), int8(368)\n",
      "memory usage: 332.4 KB\n"
     ]
    }
   ],
   "source": [
    "# convert all label columns to int8\n",
    "merged_test_df[\"user_id\"] = merged_test_df[\"user_id\"].astype(\"int16\")\n",
    "merged_test_df[\"anime_id\"] = merged_test_df[\"anime_id\"].astype(\"int16\")\n",
    "\n",
    "for col in merged_test_df.columns:\n",
    "    if col not in [\"user_id\", \"anime_id\", \"rating\", \"Duration\"]:\n",
    "        merged_test_df[col] = merged_test_df[col].astype(\"int8\")\n",
    "\n",
    "merged_test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49360 entries, 0 to 49359\n",
      "Columns: 372 entries, user_id to TV\n",
      "dtypes: float64(2), int16(2), int8(368)\n",
      "memory usage: 18.3 MB\n"
     ]
    }
   ],
   "source": [
    "# convert all label columns to int8\n",
    "merged_df[\"user_id\"] = merged_df[\"user_id\"].astype(\"int16\")\n",
    "merged_df[\"anime_id\"] = merged_df[\"anime_id\"].astype(\"int16\")\n",
    "\n",
    "for col in merged_df.columns:\n",
    "    if col not in [\"user_id\", \"anime_id\", \"rating\", \"Duration\"]:\n",
    "        merged_df[col] = merged_df[col].astype(\"int8\")\n",
    "\n",
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
